package com.debez.consumer;

import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;

import com.debez.consumer.models.*;
import com.fasterxml.jackson.databind.ObjectMapper;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.junit.After;
import org.junit.Before;
import org.junit.ClassRule;

import org.junit.jupiter.api.Test;

import org.junit.runner.RunWith;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.listener.ContainerProperties;
import org.springframework.kafka.listener.KafkaMessageListenerContainer;
import org.springframework.kafka.listener.MessageListener;
import org.springframework.kafka.test.EmbeddedKafkaBroker;
import org.springframework.kafka.test.rule.EmbeddedKafkaRule;
import org.springframework.kafka.test.utils.ContainerTestUtils;
import org.springframework.kafka.test.utils.KafkaTestUtils;
import org.springframework.test.annotation.DirtiesContext;
import org.springframework.test.context.junit4.SpringRunner;

import static org.assertj.core.api.Assertions.assertThat;
import static org.junit.Assert.assertThat;
import static org.springframework.kafka.test.assertj.KafkaConditions.key;
import static org.springframework.kafka.test.hamcrest.KafkaMatchers.hasValue;

import java.io.IOException;
import java.util.Map;

@RunWith(SpringRunner.class)
@DirtiesContext
@SpringBootTest()
public class KafkaMessageProducerTest {

  Logger LOGGER = LoggerFactory.getLogger(KafkaMessageProducerTest.class);

  @Autowired
  private KafkaMessageProducerService kafkaMessageProducerService;

  private static final String TOPIC_NAME = "topic-name";

  @ClassRule
  public static EmbeddedKafkaRule embeddedKafka = new EmbeddedKafkaRule(1, true, TOPIC_NAME);

  private KafkaMessageListenerContainer<String, String> container;

  private BlockingQueue<ConsumerRecord<String, String>> consumerRecords = new LinkedBlockingQueue<>();

  @Before
  public void setUp() {
    // consumerRecords = new LinkedBlockingQueue<>();
    ContainerProperties containerProps = new ContainerProperties(TOPIC_NAME);
    Map<String, Object> consumerProps = KafkaTestUtils.consumerProps("sender", "false", embeddedKafka.getEmbeddedKafka());
    DefaultKafkaConsumerFactory<String, String> consumer = new DefaultKafkaConsumerFactory<>(consumerProps);
    container = new KafkaMessageListenerContainer<>(consumer, containerProps);
    container.setupMessageListener((MessageListener<String, String>) record -> {
      LOGGER.debug("Listened message [{}]",record.toString());
      consumerRecords.add(record);
    });
    container.start();

    ContainerTestUtils.waitForAssignment(container, embeddedKafka.getEmbeddedKafka().getPartitionsPerTopic());
  }

  @After
  public void tearDown() {
    container.stop();
  }

  // ./gradlew clean test --tests "com.debez.consumer.KafkaMessageProducerTest"


  @Test
  public void it_should_send_event() throws InterruptedException, IOException {
    DebezRecord record = new DebezRecord().withPayload(
      new Payload().withOp("u").withSource(
        new Source().withName("name")));
    kafkaMessageProducerService.sendMessage(record);

    LOGGER.info(kafkaMessageProducerService.toString());
    LOGGER.info(consumerRecords.toString());

    ConsumerRecord<String, String> received = consumerRecords.poll(10, TimeUnit.SECONDS);

    LOGGER.info(received.toString());

    ObjectMapper mapper = new ObjectMapper();
    String json = mapper.writeValueAsString(record);
    assertThat(received, hasValue(json));
    assertThat(received).has(key(null));

  }


}